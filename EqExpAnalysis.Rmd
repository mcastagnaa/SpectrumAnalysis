---
title: "Spectrum range: volatility and exposure analysis"
author: "Matteo Castagna"
date: "May 2015"
output:
  pdf_document:
    includes:
      in_header: pdflscape.tex
    number_sections: yes
  word_document: default
---

# Introduction
This added work explores the relationship between the funds-types allocation for the Spectrum range and the volatility of returns computed using the Mid price NaV quotes.

We also quantify the extent of the undershoot vs. volatility targets as highlighted by the specialized press, we provide a measure of what would be needed (in terms of future volatility of returns) in order to achieve those targets and we also come up with ways to get there based on statistical evidence.

The underlying dataset is the same as the previous job; the funds-type allocation is collected from the Vivaldi SQL database directly via a standard query over an ODBC channel. In order to perform those queries reading rights on the Vivaldi database are needed. The resulting dataset is available as a \textit{.Rda} file with all the other relevant resources.

The raw data and all the relevant R scripts are published on <http://www.github.com/mcastagnaa/SpectrumAnalysis> and available there for replication to anybody interested. 

This is an R Markdown document\footnote{Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.}\footnote{The relevant R packages used (with all the relevant dependencies) are:

```{r LoadPackages, message=FALSE}
library(PerformanceAnalytics)
library(scales)
library(reshape2)
library(ggplot2)
library(scatterplot3d)
library(plyr)
library(Hmisc)
library(stargazer)
library(gridExtra)
```
}.

# The dataset
Spectrum funds prices are taken as delivered by Citi to OMGI. The Spectrum prices are available by class on a Bid/Mid/Offer basis. For this exercise the Mid price was used for the OA class.
Using Mid quote instead of the official one (clients will experience swings between bid and offer prices) seems to be the logical option in order to avoid any extra volatility not due to market or portfolio allocation; the OA class was used given it has the longest time series (TS).

From the prices TS the returns TSs are built using the following syntax (i.e. computing simple returns):

```r
#Returns - pseudo code

FundPRes$SpecXRet <- c(NA, FundPRes$Mid.SKSPECX[2:n]/FundPRes$Mid.SKSPECX[1:n-1]-1)
... 
# where X is 3:8
```
The Spectrum funds returns and the VIX index levels\footnote{This is actually a difference vs. the same data set which was used for the previous work. The VIX index levels (a measure of the S\&P implied volatility on each given day) are sourced from Bloomberg - the relevant .csv file is part of the resources.} are part of the data frame saved with name \textit{CombByDate.Rda}.

The relevant funds allocation and risk allocations are obtained using the following code which stores the relevant information in a data frame saved with name \textit{SpecExpSet.Rda}.

```r
#SpecExpSet.Rda - pseudo code

library(RODBC)
rm(list =ls(all=TRUE))

channel <- odbcConnect("SQLServerVivaldi")
SpecX <- as.data.frame(sqlQuery(channel, "EXEC spS_GetFoFTypeLoading1Y '2015 Apr 30', ID"))
SpecX$Fund <- as.factor("SpecX")
...
# where X = 3:8 and ID = 126:131

SpecExpSet <- rbind(Spec3, Spec4, Spec5, Spec6, Spec7, Spec8)
SpecExpSet$DetsDate <- as.Date(SpecExpSet$DetsDate)
rm(list=ls()[ls() != "SpecExpSet"])
save(SpecExpSet, file = "SpecExpSet.Rda")
```

The two dataset are then combined to generate the data frame used for the rest of this analysis.

```{r CreateRegSet, echo=FALSE}
rm(list =ls(all=TRUE))

load("SpecExpSet.Rda")
load("CombByDate.Rda")

RollingObs <- 20

FundsExp <- reshape(SpecExpSet[SpecExpSet$Calc == "NetExp" &
                                SpecExpSet$Class =="ByFundType" &
                                SpecExpSet$Typ == "Equity Fund" & 
                                SpecExpSet$DetsDate != as.Date("2014-12-12"),
                               ],  
                    drop = c("Typ", "Class", "Calc"),
                    idvar = c("DetsDate"),
                    timevar = "Fund", 
                    direction = "wide")
names(FundsExp) <- c("Date", 
                     "Spec3EqFuExp", 
                     "Spec4EqFuExp", 
                     "Spec5EqFuExp",
                     "Spec6EqFuExp",
                     "Spec7EqFuExp",
                     "Spec8EqFuExp")
FundsExp <- FundsExp[complete.cases(FundsExp),]
RollFuExpAv <- data.frame(cbind(FundsExp$Date, 
                              rollapplyr(FundsExp[c("Spec3EqFuExp", 
                                                   "Spec4EqFuExp", 
                                                   "Spec5EqFuExp", 
                                                   "Spec6EqFuExp", 
                                                   "Spec7EqFuExp", 
                                                   "Spec8EqFuExp")], 
                                         RollingObs, mean, fill=NA)))
colnames(RollFuExpAv)[1] <- "Date"
RollFuExpAv$Date <- as.Date(RollFuExpAv$Date)
# 
# 
# EquityExp <- reshape(SpecExpSet[SpecExpSet$Calc == "NetExp" &
#                                 SpecExpSet$Class =="BySecGroup" &
#                                 SpecExpSet$Typ == "Equities"&
#                                 SpecExpSet$DetsDate != as.Date("2014-12-12"),
#                                 ],  
#                     drop = c("Typ", "Class", "Calc"),
#                     idvar = c("DetsDate"),
#                     timevar = "Fund", 
#                     direction = "wide")
# names(EquityExp) <- c("Date", 
#                       "Spec3EqExp", 
#                       "Spec4EqExp", 
#                       "Spec5EqExp",
#                       "Spec6EqExp",
#                       "Spec7EqExp",
#                       "Spec8EqExp")
# EquityExp <- FundsExp[complete.cases(EquityExp),]
# 
# RollEqExpAv <- data.frame(cbind(EquityExp$Date, 
#                                 rollapplyr(EquityExp[c("Spec3EqExp", 
#                                                       "Spec4EqExp", 
#                                                       "Spec5EqExp", 
#                                                       "Spec6EqExp", 
#                                                       "Spec7EqExp", 
#                                                       "Spec8EqExp")], 
#                                            RollingObs, mean, fill=NA)))
# colnames(RollEqExpAv)[1] <- "Date"
# RollEqExpAv$Date <- as.Date(RollEqExpAv$Date)
# 
##########################
# Pick the "right" exposure variable
# RollFuExAv for equity funds exposure
# RollEqExAv for equity exposure
ExpRollMelt <- melt(RollFuExpAv, id.var = c("Date"), value.name = "Exposure")
ExpRollMelt$variable <- substr(ExpRollMelt$variable, 1, 5)

###########################
Returns <- subset(CombByDate, select = c(Date,
                                         Spec3Ret,
                                         Spec4Ret,
                                         Spec5Ret,
                                         Spec6Ret,
                                         Spec7Ret,
                                         Spec8Ret,
                                         VIX)
)

RollRetSd <- data.frame(cbind(Returns$Date, 
                           rollapplyr(Returns[c("Spec3Ret", 
                                                "Spec4Ret", 
                                                "Spec5Ret", 
                                                "Spec6Ret", 
                                                "Spec7Ret", 
                                                "Spec8Ret")], 
                                      RollingObs, sd, fill=NA)))
colnames(RollRetSd)[1] <- "Date"

RollRetSd$Date <- as.Date(RollRetSd$Date)

RetSdRollMelt <- melt(RollRetSd, id.var=c("Date"), value.name = "SdRet")
RetSdRollMelt$variable <- substr(RetSdRollMelt$variable, 1, 5)

############
VIXdf <- data.frame(cbind(Returns$Date, 
                              rollapplyr(Returns[c("VIX")], 
                                         RollingObs, mean, fill=NA)))
colnames(VIXdf)[1] <- "Date"
VIXdf$Date <- as.Date(VIXdf$Date)
############

RegSet <- merge(ExpRollMelt, RetSdRollMelt, by = c("Date", "variable"))
RegSet <- merge(RegSet, VIXdf, by = "Date")
RegSet$VixCut <- cut(RegSet$VIX, 3)
RegSet$VixCutLab <- cut(RegSet$VIX, 3, labels = c("low", "mid", "hi"))
RegSet$VixCutCol <- cut(RegSet$VIX, 3, labels = c(3, 4, 2))
```

Couple of notes on the dataset:
\begin{enumerate}
  \item The asset class for the funds held in each Spectrum fund is the one provided by Bloomberg;
  \item Volatility of the Spectrum funds returns is calculated using `r RollingObs` rolling observations of daily returns (without annualizing);
  \item The asset allocation and the VIX level are averaged over the same number of observations.
\end{enumerate}

# Data inspection
The relevant asset allocation for the different funds can be described by \textbf{panel 1}. The allocation to the different fund types is pretty much constant over the period observed. The relevant differences, across the range, are concentrated in the percentage of equity funds and debt funds.

\begin{landscape}[!htb]
\textbf{Panel 1: Spectrum funds - fund type allocation}
```{r AASpectrum, echo=FALSE, fig.align='center', fig.width=9, fig.height=6}
FundExpTypeSet <- SpecExpSet[SpecExpSet$Class == "ByFundType" &
                        SpecExpSet$Calc == "NetExp" & 
                        SpecExpSet$DetsDate != as.Date("2014-12-12"), 
                      c("DetsDate", "Val", "Fund", "Typ")]
rownames(FundExpTypeSet) <- NULL

ggplot(data = FundExpTypeSet[complete.cases(FundExpTypeSet),] , 
       aes(DetsDate,  Val)) + 
  geom_area(aes(colour = Typ, fill = Typ), position = 'stack') +
  scale_fill_brewer(palette="Greens") + 
  scale_y_continuous(labels = percent) +
  facet_wrap(~ Fund) + 
  theme(axis.text=element_text(size=7))
```
\end{landscape}

Running boxplot charts reveals that there are no particular outliers for the rolling volatility observations and the Equity funds exposure ones. 

```{r BPChecks, echo=FALSE, warning=FALSE, fig.align='center', fig.width=7, fig.height=3}
p1 <- ggplot(RetSdRollMelt, aes(x=variable, y = SdRet)) +
  geom_boxplot() + 
  scale_y_continuous(labels = percent) +
  theme(axis.title.x=element_blank())

p2 <- ggplot(ExpRollMelt, aes(x=variable, y = Exposure)) +
  geom_boxplot() +
  scale_y_continuous(labels = percent) +
  theme(axis.title.x=element_blank())
grid.arrange(p1, p2, ncol = 2, main = "")

```


# Analysis
Without adding any state variable we already have a decent fit:

```{r ExpLm, echo=FALSE, warning=FALSE, results='hide'}
SDonEXP <- lm(SdRet ~ Exposure, data = RegSet)
summary(SDonEXP)
```

\begin{table}[H]\centering 
  \caption{Regression results} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}}lc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
\\[-1.8ex] & SdRet \\ 
\hline \\[-1.8ex] 
 Exposure & 0.00534$^{***}$ \\ 
  & (0.00017) \\ 
  & \\ 
 Constant & 0.00051$^{***}$ \\ 
  & (0.00009) \\ 
  & \\ 
Observations & 1,152 \\ 
R$^{2}$ & 0.45348 \\ 
Adjusted R$^{2}$ & 0.45300 \\ 
Residual Std. Error & 0.00094 (df = 1150) \\ 
F Statistic & 954.20780$^{***}$ (df = 1; 1150) \\ 
\hline \\[-1.8ex] 
\textit{Notes:} & \multicolumn{1}{l}{$^{***}$Significant at the 1 percent level.} \\ 
 & \multicolumn{1}{l}{$^{**}$Significant at the 5 percent level.} \\ 
 & \multicolumn{1}{l}{$^{*}$Significant at the 10 percent level.} \\ 
\end{tabular} 
\end{table} 

Using a graphical representation we have the following plot:

```{r plainLmChart, echo=FALSE, warning=FALSE, fig.align='center', fig.width=6, fig.height=4}
ggplot(RegSet, aes(x=Exposure, y = SdRet)) + 
  geom_smooth(method="lm") + 
  geom_point(shape=1) + 
  labs(x = "Eq.Funds exposure", y = "StDev of returns") +
  ggtitle(paste("Rolling", RollingObs, "observations"))
```

What the regression results are telling us is: if we rise the allocation to equity funds by 0.1 (e.g. from 30% to 40%) the resulting standard deviation of daily returns increases by `r paste0(round(SDonEXP[[1]][2]*0.1*10000,1), "bps")`. That is from `r paste0(round((SDonEXP[[1]][1]+SDonEXP[[1]][2]*0.3)*100,3), "%")` to `r paste0(round((SDonEXP[[1]][1]+SDonEXP[[1]][2]*0.4)*100,3), "%")` (that is from `r paste0(round((SDonEXP[[1]][1]+SDonEXP[[1]][2]*0.3*sqrt(252))*100,1), "%")` to `r paste0(round((SDonEXP[[1]][1]+SDonEXP[[1]][2]*0.4*sqrt(252))*100,1), "%")` in annualized terms).

Intuitively adding a state variable describing the market level of volatility makes sense: higher market volatility will lead \textit{coeteris paribus} to a higher fund volatility.
This is immediately visible if we split the sample by three different level of the VIX index.

```{r VIXSetsplitReg, echo=FALSE, warning=FALSE, fig.align='center'}
ggplot(RegSet, aes(x=Exposure, y = SdRet
                   , colour = factor(VixCut))) + 
  geom_smooth(method="lm") + 
  geom_point(shape=1) +
  labs(x = "Eq.Funds exposure", y = "StDev of returns") +
  ggtitle(paste("Rolling", RollingObs, "observations"))
```

Running again a OLS regression and adding the VIX index as an explanatory variable greatly enhance the amount of Spectrum volatility of StDev explained by the regressors:

```{r VIXLm, echo=FALSE, warning=FALSE, results='hide'}
SDonEXPVix <- lm(SdRet ~ Exposure + VIX, data = RegSet)
summary(SDonEXPVix)
```

\begin{table}[H] \centering 
  \caption{Regression results} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}}lc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
\\[-1.8ex] & SdRet \\ 
\hline \\[-1.8ex] 
 Exposure & 0.00530$^{***}$ \\ 
  & (0.00014) \\ 
  & \\ 
 VIX & 0.02466$^{***}$ \\ 
  & (0.00091) \\ 
  & \\ 
 Constant & $-$0.00313$^{***}$ \\ 
  & (0.00015) \\ 
  & \\ 
Observations & 1,152 \\ 
R$^{2}$ & 0.66576 \\ 
Adjusted R$^{2}$ & 0.66517 \\ 
Residual Std. Error & 0.00074 (df = 1149) \\ 
F Statistic & 1,144.30500$^{***}$ (df = 2; 1149) \\ 
\hline \\[-1.8ex] 
\textit{Notes:} & \multicolumn{1}{l}{$^{***}$Significant at the 1 percent level.} \\ 
 & \multicolumn{1}{l}{$^{**}$Significant at the 5 percent level.} \\ 
 & \multicolumn{1}{l}{$^{*}$Significant at the 10 percent level.} \\ 
\end{tabular} 
\end{table} 

Graphically:
```{r VIXRegChart, echo=FALSE, warning=FALSE, fig.align='center', fig.width=6, fig.height=5.5}
scatterplot3d(RegSet$VIX,RegSet$Exposure,RegSet$SdRet, 
              xlab = "VIX level", ylab = "Exposure level", 
              zlab = "St.Dev of returns", box = TRUE, angle=60, 
              cex.symbols = 0.5, cex.axis = 0.5, cex.lab = 0.75,
              color = RegSet$VixCutCol)
#sc3d$plane3d(SDonEXPVix)

```

The regression provides a much improved fit and the coefficients provide the following insights:
\begin{enumerate}
  \item \textit{coeteris paribus} if we rise the exposure to equity funds by 0.1 (e.g. going from 20\% to 30\%) the resulting daily volatility will increase by `r paste0(round(SDonEXPVix[[1]][2]*0.1*10000,1), "bps")`;
  \item \textit{coeteris paribus} if the market volatility rises by 0.01 (e.g. going from 15\% to 16\%) the resulting daily volatility of the fund will increase by `r paste0(round(SDonEXPVix[[1]][3]*0.01*10000,1), "bps")`
\end{enumerate}

A different way to see that story can be achieved by slicing the volatility levels in N sets by cutting the different observations. Using the same cuts we used in the chart with the three different regressions (N = 3) and labelling them as "low", "mid" and "hi" we get the following results:

```{r VIXCutLm, echo=FALSE, warning=FALSE, results='hide'}
SDonEXPVixC <- lm(SdRet ~ Exposure + VixCutLab, data = RegSet)
summary(SDonEXPVixC)
```

\begin{table}[H] \centering 
  \caption{Regression results} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}}lc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
\\[-1.8ex] & SdRet \\ 
\hline \\[-1.8ex] 
 Exposure & 0.00531$^{***}$ \\ 
  & (0.00014) \\ 
  & \\ 
 VixCutLabmid & 0.00059$^{***}$ \\ 
  & (0.00005) \\ 
  & \\ 
 VixCutLabhi & 0.00136$^{***}$ \\ 
  & (0.00006) \\ 
  & \\ 
 Constant & $-$0.00004 \\ 
  & (0.00008) \\ 
  & \\ 
Observations & 1,152 \\ 
R$^{2}$ & 0.63752 \\ 
Adjusted R$^{2}$ & 0.63657 \\ 
Residual Std. Error & 0.00077 (df = 1148) \\ 
F Statistic & 673.02270$^{***}$ (df = 3; 1148) \\ 
\hline \\[-1.8ex] 
\textit{Notes:} & \multicolumn{1}{l}{$^{***}$Significant at the 1 percent level.} \\ 
 & \multicolumn{1}{l}{$^{**}$Significant at the 5 percent level.} \\ 
 & \multicolumn{1}{l}{$^{*}$Significant at the 10 percent level.} \\ 
\end{tabular} 
\end{table} 

Those coefficients provide you with the measure of the "jumps" in the volatility of returns due to changing status in the market volatility.

We can say:
\begin{enumerate}
  \item \textit{coeteris paribus} if we rise the exposure to equity funds by 0.1 (e.g. going from 20\% to 30\%) the resulting daily volatility will increase by `r paste0(round(SDonEXPVixC[[1]][2]*0.1*10000,1), "bps")`;
  \item \textit{coeteris paribus} if the market volatility rises from "low" to "mid" the resulting daily volatility of the fund will increase by `r paste0(round(SDonEXPVixC[[1]][3]*10000,1), "bps")`
  \item \textit{coeteris paribus} if the market volatility rises from "low" to "hi" the resulting daily volatility of the fund will increase by `r paste0(round(SDonEXPVixC[[1]][4]*10000,1), "bps")`
\end{enumerate}

# Risk allocation from exposure allocation
A more direct way to illustrate how powerful the allocation to equity funds is for the realized volatility of the Spectrum range, is analysing the contribution to the expected volatility using marginal VaR\footnote{That is the contribution of each portfolio line to the overall VaR}.

We can describe that via \textbf{panel 2}. 

While in \underline{exposure terms} the allocation to other sectors is visible, it almost disappears in \underline{risk terms}\footnote{The last few months need investigation given that the risk associated with real estate and other types seems to vanish without any easy explanation!}.

\begin{landscape}[!htb]
\textbf{Panel 2: Spectrum funds - risk contribution by fund type}
```{r RASpectrum, echo=FALSE, fig.align='center', fig.width=9, fig.height=6}
FundExpTypeSet <- SpecExpSet[SpecExpSet$Class == "ByFundType" &
                        SpecExpSet$Calc == "RiskShare" & 
                        SpecExpSet$DetsDate != as.Date("2014-12-12"), 
                      c("DetsDate", "Val", "Fund", "Typ")]
rownames(FundExpTypeSet) <- NULL

ggplot(data = FundExpTypeSet[complete.cases(FundExpTypeSet),] , 
       aes(DetsDate,  Val)) + 
  geom_area(aes(colour = Typ, fill = Typ), position = 'stack') +
  scale_fill_brewer(palette="Greens") + 
  scale_y_continuous(labels = percent) +
  facet_wrap(~ Fund) + 
  theme(axis.text=element_text(size=7))
```
\end{landscape}

# Where to now?
It was discussed several times during the Quarterly Investment Committee the potential issue around the Spectrum range realized volatility not being aligned with what it was promised to the clients. 

This seems to be of interest for the specialized press as well as you can see \href{http://www.fundweb.co.uk/news-and-analysis/multi-manager/old-mutual-risk-targeted-spectrum-range-undershoots-volatility-and-returns/2019026.article}{here}
\footnote{http://www.fundweb.co.uk/news-and-analysis/multi-manager/old-mutual-risk-targeted-spectrum-range-undershoots-volatility-and-returns/2019026.article} as an example.

The same article provides an idea of how big the undershoot is. Using the mid point of the target volatility we can measure (in annualized terms this time) how much we are away from it (as of end of December 2014, since inception date 28 April 2008).

```{r Table1, echo=FALSE, fig.align='center'}
PeriodPast <- as.numeric((as.Date("2014/12/31")-as.Date("2008/04/28"))/365)
PeriodLeft <- as.numeric((as.Date("2018/04/28")-as.Date("2014/12/31"))/365)

SpecTgtVol <- data.frame(Fund = c("Spec3", "Spec4","Spec5",
                                  "Spec6","Spec7","Spec8"),
                         Min = c(0.0575, 0.0786, 0.0957, 0.1129, 0.13, 0.1472),
                         Max = c(0.0785, 0.0956, 0.1128, 0.1299, 0.1471, 0.1643),
                         SIDec14 = c(0.0496, 0.0621, 0.0758, 0.0897, 0.1049, 0.1233))
rownames(SpecTgtVol) <- SpecTgtVol$Fund

SpecTgtVol$Mid <- with(SpecTgtVol,
                            (Min + (Max-Min)/2))

SpecTgtVol$DistFromMid <- with(SpecTgtVol,
                            SIDec14 - Mid)

SpecTgtVol$DistFromMidBps <- with(SpecTgtVol,
                            round(DistFromMid*10000,0))

textplot(
  format.df(SpecTgtVol[c("SIDec14", "Mid", "DistFromMid", "DistFromMidBps")],
          cdec = c(4,4,4,0), numeric.dollar = FALSE),
  cex = 0.75  
  )
```

Based on that measure and the amount of time left for the end of the first decade\footnote{The volatility target is "promised" over a ten years periods} of the Spectrum life (`r paste(round(PeriodLeft, 1), "years")`) and using the results of the regression, we can estimate how bigger the allocation to equity needs to be or how much more volatility in the equity market we need in order to achieve the target.

The following table gives an idea of how much realized volatility of returns we need in order to achieve the target mid-point (Mid labels) and low-point (Min labels).

```{r Table2, echo=FALSE, fig.align='center'}
SpecTgtVol$NextPerMid <- with(SpecTgtVol,
                              sqrt((10*Mid^2 - PeriodPast * SIDec14^2)/PeriodLeft)
                              )
SpecTgtVol$JumpMid <-  with(SpecTgtVol,
                              round((NextPerMid-SIDec14)*10000,0)
                              )

SpecTgtVol$NextPerMin <- with(SpecTgtVol,
                              sqrt((10*Min^2 - PeriodPast * SIDec14^2)/PeriodLeft)
                              )
SpecTgtVol$JumpMin <-  with(SpecTgtVol,
                              round((NextPerMin-SIDec14)*10000,0)
                              )
textplot(
  format.df(SpecTgtVol[c("SIDec14", "Mid", "NextPerMid", "JumpMid",
                         "Min", "NextPerMin", "JumpMin")],
            cdec = c(4,4,4,0,4,4,0), numeric.dollar = FALSE),
  cex = 0.75  
  )         
```

The next period volatility (NextPer* columns) has been calculated, in approximate format assuming an average of daily returns equal to zero, as:

\[SD(b_i) = \sqrt{\frac{(n+m)*SD^2(tgt) - n * SD^2(a_i)}{m}}\]

Where $SD(b_i)$ is the volatility of the future period $m$ needed to achieve the overall volatility of $SD(tgt)$ after an initial period $n$ volatility of $SD(a_i)$.

Annualizing the previous regression results, we know that an increase by 10% in equity allocation leads to an increase of realized volatility (based on non-swung prices) of `r paste0(round(SDonEXPVix[[1]][2]*sqrt(252)*0.1*10000,1), "bps")`.
But we have to be mindful of the limitation in terms of how much equity we can place in order to stay in the selected universe\footnote{The Spectrum funds are in the unassigned IMA sector but the objective is to beat a relevant IMA Mix sector on volatility-adjusted basis}.

The table below provides the average allocation to the equity funds for the different products:
```{r colmeans, echo=FALSE, fig.align='center'}
textplot(
  format.df(colMeans(FundsExp[,-1], na.rm=TRUE),
            dec = 2, numeric.dollar = FALSE),
  cex = 0.75  
  )  
#round(colMeans(FundsExp[,-1], na.rm=TRUE),2)
```

Alternatively we can simply \textit{hope} to have a higher level of equity market volatility (proxy-ed by the S&P volatility).
In that respect, again using the regression results, we can say that we need a jump worth `r paste0(round((0.05/sqrt(252))/SDonEXPVix[[1]][3]*100,1), "%")` for the VIX in order to get a 500bps rise in the annualized volatility of the fund, as an example.

We need to be mindful that the realized volatility for the client is enhanced by the swing price convention: there is potentially a significant difference between the volatility computed on official NaVs and the most recent three years\footnote{We also need to add that the since inception data contain the very volatile period between 2008 and 2009} set we used to calculate the volatility of the funds for the previous exercise based on non-swung NaV quotes:

```{r SIvs3y, echo=FALSE, fig.align='center'}
colnames(Returns) <- c("Date", "Spec3", "Spec4", "Spec5",
                       "Spec6", "Spec7", "Spec8", "VIX")
SpecRetsMolten <- melt(Returns[,-8], id.vars = "Date")
SpecVol <- ddply(SpecRetsMolten, ~ variable, colwise(sd))
colnames(SpecVol) <- c("Fund", "Date", "StDev3yAnn")

SpecVol$StDev3yAnn <- SpecVol$StDev3yAnn * sqrt(252)
SpecVol <- subset(SpecVol, select = c("Fund", "StDev3yAnn"))

SpecTgtVol <- merge(SpecTgtVol, SpecVol, by = "Fund")

textplot(
  format.df(SpecTgtVol[c("Fund","SIDec14", "StDev3yAnn")],
            dec = 3, numeric.dollar = FALSE),
  cex = 0.75  
  )  
```

# Conclusions
This work tries to quantify how important is the equity portion of the Spectrum portfolios for their realized volatility of returns.

While the exposure is reasonable and aligned to the relevant IMA sectors, the share of the overall risk is clearly eclipsing any other fund-type held.

A simple regression model shows the relationship between the realized volatility of returns, the equity-funds exposure and the generic level of market volatility.
Those results can be used to consider how the target volatility for the Spectrum range can be achieved.

The realized volatility over the last `r round(PeriodPast,1)` years (to end of December 2014) is significantly below the promised range; we measure how much the realized volatility needs to rise in what is left for the first decade of life for Spectrum in order to achieve the objective. 

Rising the equity allocation or hoping for a more volatile markets (or a combination of the two) are obvious options. This is not an easy one to pull off successfully; typically, a sudden fall in market prices is associated to higher volatility: a circumstance where you clearly do not want to have a higher allocation to equities. On the other hand relying on "hope" (waiting for volatility events pushing higher the period averages) sounds as an unpalatable option as well.
